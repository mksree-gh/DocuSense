{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NumberObject(b'-') invalid; use 0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty file: attachment (1).pdf\n",
      "Skipping empty file: attachment (5).pdf\n",
      "Skipping empty file: attachment (6).pdf\n",
      "Error reading file: attachment (7).pdf - 'NumberObject' object is not subscriptable\n",
      "Skipping empty file: attachment.pdf\n",
      "Error reading file: ePAN_CYWPM4396M.pdf - File has not been decrypted\n",
      "Error reading file: national-audit-pressure-ulcer-prevalence-england-cross-sectional-study.pdf - [Errno 22] Invalid argument\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x6439e for key /Info\n",
      "Multiple definitions in dictionary at byte 0x643ab for key /Info\n",
      "Multiple definitions in dictionary at byte 0x643b8 for key /Info\n",
      "Multiple definitions in dictionary at byte 0x3076e for key /Info\n",
      "Multiple definitions in dictionary at byte 0x3077a for key /Info\n",
      "Multiple definitions in dictionary at byte 0x30786 for key /Info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file: UTIITSL_ePAN_CYWPM4396M_03042023_213849.pdf - File has not been decrypted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>File Size (kb)</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Date Modified</th>\n",
       "      <th>Date Accessed</th>\n",
       "      <th>Number of Pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-IH-comprehensive-intellectual-humility.pdf</td>\n",
       "      <td>98.156250</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>05-04-2023 15:49:53</td>\n",
       "      <td>22-05-2023 08:59:44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-lit-review-Measuring-Intellectual-Humility-...</td>\n",
       "      <td>631.642578</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>05-04-2023 15:49:54</td>\n",
       "      <td>22-05-2023 08:59:44</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_Task Scheduling CSP.pdf</td>\n",
       "      <td>2907.464844</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>16-04-2023 11:54:27</td>\n",
       "      <td>22-05-2023 08:59:44</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-Intellectual Humility An Introduction to the...</td>\n",
       "      <td>6906.728516</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>05-04-2023 15:50:22</td>\n",
       "      <td>22-05-2023 08:59:44</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-s2.0-S0141933118304629-main.pdf</td>\n",
       "      <td>1779.131836</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>01-11-2022 13:35:09</td>\n",
       "      <td>22-05-2023 08:59:44</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>week4.pdf</td>\n",
       "      <td>3177.144531</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>24-02-2023 11:04:29</td>\n",
       "      <td>22-05-2023 08:59:49</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Week5_lessson.pdf</td>\n",
       "      <td>189.061523</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>16-10-2022 20:21:58</td>\n",
       "      <td>22-05-2023 08:59:49</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Wireless Compact Laser Vibrometer EDITED (1).pdf</td>\n",
       "      <td>1663.701172</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>19-08-2022 02:27:09</td>\n",
       "      <td>22-05-2023 08:59:49</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Wireless Compact Laser Vibrometer EDITED.pdf</td>\n",
       "      <td>1663.701172</td>\n",
       "      <td>21-05-2023 21:28:44</td>\n",
       "      <td>19-08-2022 02:27:05</td>\n",
       "      <td>22-05-2023 08:59:49</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Zaid Ahmed Khan Certificate.pdf</td>\n",
       "      <td>77.344727</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>09-11-2022 18:35:44</td>\n",
       "      <td>22-05-2023 08:59:49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File Name  File Size (kb)   \n",
       "0        03-IH-comprehensive-intellectual-humility.pdf       98.156250  \\\n",
       "1    04-lit-review-Measuring-Intellectual-Humility-...      631.642578   \n",
       "2                            0_Task Scheduling CSP.pdf     2907.464844   \n",
       "3    1-Intellectual Humility An Introduction to the...     6906.728516   \n",
       "4                    1-s2.0-S0141933118304629-main.pdf     1779.131836   \n",
       "..                                                 ...             ...   \n",
       "411                                          week4.pdf     3177.144531   \n",
       "412                                  Week5_lessson.pdf      189.061523   \n",
       "413   Wireless Compact Laser Vibrometer EDITED (1).pdf     1663.701172   \n",
       "414       Wireless Compact Laser Vibrometer EDITED.pdf     1663.701172   \n",
       "415                    Zaid Ahmed Khan Certificate.pdf       77.344727   \n",
       "\n",
       "            Date Created        Date Modified        Date Accessed   \n",
       "0    21-05-2023 21:28:42  05-04-2023 15:49:53  22-05-2023 08:59:44  \\\n",
       "1    21-05-2023 21:28:42  05-04-2023 15:49:54  22-05-2023 08:59:44   \n",
       "2    21-05-2023 21:28:42  16-04-2023 11:54:27  22-05-2023 08:59:44   \n",
       "3    21-05-2023 21:28:42  05-04-2023 15:50:22  22-05-2023 08:59:44   \n",
       "4    21-05-2023 21:28:42  01-11-2022 13:35:09  22-05-2023 08:59:44   \n",
       "..                   ...                  ...                  ...   \n",
       "411  21-05-2023 21:18:03  24-02-2023 11:04:29  22-05-2023 08:59:49   \n",
       "412  21-05-2023 21:18:03  16-10-2022 20:21:58  22-05-2023 08:59:49   \n",
       "413  21-05-2023 21:18:03  19-08-2022 02:27:09  22-05-2023 08:59:49   \n",
       "414  21-05-2023 21:28:44  19-08-2022 02:27:05  22-05-2023 08:59:49   \n",
       "415  21-05-2023 21:18:03  09-11-2022 18:35:44  22-05-2023 08:59:49   \n",
       "\n",
       "     Number of Pages  \n",
       "0                  3  \n",
       "1                 11  \n",
       "2                  9  \n",
       "3                369  \n",
       "4                 14  \n",
       "..               ...  \n",
       "411               94  \n",
       "412                4  \n",
       "413               12  \n",
       "414               12  \n",
       "415                1  \n",
       "\n",
       "[416 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "from datetime import datetime\n",
    "\n",
    "# Path of the PDFs folder\n",
    "pdfs_folder = \"All_PDFs\"\n",
    "\n",
    "# Initialize empty lists for each column\n",
    "file_names = []\n",
    "file_sizes_kb = []\n",
    "dates_created = []\n",
    "dates_modified = []\n",
    "dates_accessed = []\n",
    "num_pages = []\n",
    "\n",
    "# Loop through each PDF file in the folder\n",
    "for file_name in os.listdir(pdfs_folder):\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(pdfs_folder, file_name)\n",
    "        \n",
    "        # Check if the file is empty\n",
    "        if os.path.getsize(file_path) == 0:\n",
    "            print(f\"Skipping empty file: {file_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Extract information from the non-empty PDF file\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            try:\n",
    "                pdf = PdfReader(f)\n",
    "                file_size_bytes = os.path.getsize(file_path)\n",
    "                file_size_kb = file_size_bytes/1024\n",
    "                date_created = os.path.getctime(file_path)\n",
    "                date_modified = os.path.getmtime(file_path)\n",
    "                date_accessed = os.path.getatime(file_path)\n",
    "                pages = len(pdf.pages)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file: {file_name} - {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Convert timestamp to datetime object and format it\n",
    "        date_created = datetime.fromtimestamp(date_created).strftime('%d-%m-%Y %H:%M:%S')\n",
    "        date_modified = datetime.fromtimestamp(date_modified).strftime('%d-%m-%Y %H:%M:%S')\n",
    "        date_accessed = datetime.fromtimestamp(date_accessed).strftime('%d-%m-%Y %H:%M:%S')\n",
    "        # Append the extracted information to the respective lists\n",
    "        file_names.append(file_name)\n",
    "        file_sizes_kb.append(file_size_kb)\n",
    "        dates_created.append(date_created)\n",
    "        dates_modified.append(date_modified)\n",
    "        dates_accessed.append(date_accessed)\n",
    "        num_pages.append(pages)\n",
    "\n",
    "# Create a DataFrame from the collected information\n",
    "data = {\n",
    "    \"File Name\": file_names,\n",
    "    \"File Size (kb)\": file_sizes_kb,\n",
    "    \"Date Created\": dates_created,\n",
    "    \"Date Modified\": dates_modified,\n",
    "    \"Date Accessed\": dates_accessed,\n",
    "    \"Number of Pages\": num_pages\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pdfs = 416\n",
      "Total memory occupied by pdfs = 958.0769453048706 MB\n",
      "Number of pdfs not opened since 6 months =  0\n",
      "Number of pdfs not modified since 6 months =  272\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "df['Date Accessed'] = pd.to_datetime(df['Date Accessed'], format='%d-%m-%Y %H:%M:%S')\n",
    "df['Date Modified'] = pd.to_datetime(df['Date Modified'], format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "\n",
    "print(f\"Number of pdfs = {df.shape[0]}\")\n",
    "total_memory = df[\"File Size (kb)\"].sum() / 1024\n",
    "\n",
    "print(f\"Total memory occupied by pdfs = {total_memory} MB\")\n",
    "\n",
    "time_gap = datetime.now() - timedelta(days=182)\n",
    "filtered_df = df[df['Date Accessed'] < time_gap]\n",
    "filtered_df2 = df[df['Date Modified'] < time_gap]\n",
    "\n",
    "\n",
    "count = filtered_df.shape[0]\n",
    "count2 = filtered_df2.shape[0]\n",
    "\n",
    "print(\"Number of pdfs not opened since 6 months = \", count)\n",
    "print(\"Number of pdfs not modified since 6 months = \", count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate sets: 382\n",
      "Total number of duplicate files (excluding first files): 45\n",
      "Duplicate files:  ['AI4CPS_Search_1 (1).pdf', 'AI4CPS_Search_1.pdf']\n",
      "Duplicate files:  ['attachment (1).pdf', 'attachment (5).pdf', 'attachment (6).pdf', 'attachment.pdf']\n",
      "Duplicate files:  ['attachment (10).pdf', 'attachment (9).pdf']\n",
      "Duplicate files:  ['attachment (2).pdf', 'attachment (3).pdf']\n",
      "Duplicate files:  ['BTP-1 Consent Form (1).pdf', 'BTP-1 Consent Form.pdf']\n",
      "Duplicate files:  ['CCU_NAG_2022-08-24_OLWZVS (1).pdf', 'CCU_NAG_2022-08-24_OLWZVS (2).pdf', 'CCU_NAG_2022-08-24_OLWZVS.pdf']\n",
      "Duplicate files:  ['CentuRITon_Idea_AuReal_PPT (1).pdf', 'CentuRITon_Idea_AuReal_PPT.pdf']\n",
      "Duplicate files:  ['DOC-20230207-WA0000. (1).pdf', 'DOC-20230207-WA0000..pdf']\n",
      "Duplicate files:  ['downloadRegistrationCard (1).pdf', 'downloadRegistrationCard.pdf']\n",
      "Duplicate files:  ['ePAN_CYWPM4396M.pdf', 'UTIITSL_ePAN_CYWPM4396M_03042023_213849.pdf']\n",
      "Duplicate files:  ['FAQ_2023_Application-Requirements (1).pdf', 'FAQ_2023_Application-Requirements.pdf']\n",
      "Duplicate files:  ['Final_Schedule_for_SIH_2022_Software_25_to_26th_August_2022_2 (1).pdf', 'Final_Schedule_for_SIH_2022_Software_25_to_26th_August_2022_2 (2).pdf', 'Final_Schedule_for_SIH_2022_Software_25_to_26th_August_2022_2 (3).pdf', 'Final_Schedule_for_SIH_2022_Software_25_to_26th_August_2022_2.pdf']\n",
      "Duplicate files:  ['FTS-koren (1).pdf', 'FTS-koren.pdf']\n",
      "Duplicate files:  ['Gmail - Final Report Submission Problem Statement-1 (1) (1).pdf', 'Gmail - Final Report Submission Problem Statement-1 (1).pdf']\n",
      "Duplicate files:  ['IIT Kanpur Webmail __ [Meug] JHU-MechE Summer Intership Program for Rising Seniors (1).pdf', 'IIT Kanpur Webmail __ [Meug] JHU-MechE Summer Intership Program for Rising Seniors.pdf']\n",
      "Duplicate files:  ['Keerthi Sree Marrapu (1).pdf', 'Keerthi Sree Marrapu.pdf']\n",
      "Duplicate files:  ['kupdf.net_heat-transfer-by-yvc-rao.pdf', 'qdoc.tips_heat-transfer-by-yvc-rao.pdf']\n",
      "Duplicate files:  ['me_ntmp_18_ps_intro (1).pdf', 'me_ntmp_18_ps_intro.pdf']\n",
      "Duplicate files:  ['Micro_2014-2015 (1).pdf', 'Micro_2014-2015.pdf']\n",
      "Duplicate files:  ['Micro_2022-2023.pdf', 'Micro_2022-2023_Updated.pdf']\n",
      "Duplicate files:  ['MKSree_CV (4) (1).pdf', 'MKSree_CV (4).pdf']\n",
      "Duplicate files:  ['MKSree_ERP_CV1 (1).pdf', 'MKSree_ERP_CV1.pdf']\n",
      "Duplicate files:  ['MKS_CV_Jul_2022.pdf', 'MKS_CV_Jul_2022_ERP_Verified (1).pdf', 'MKS_CV_Jul_2022_ERP_Verified.pdf']\n",
      "Duplicate files:  ['pdfcoffee.com_a-textbook-of-vastuvidya-prabhu-1996-3-pdf-free.pdf', 'toaz.info-a-textbook-of-vastuvidya-prabhu-1996-pr_c3b9e6b585ea60d200ef191456b68ca9.pdf']\n",
      "Duplicate files:  ['Problem 1_Raunak Raj_Final Concept Note (1).pdf', 'Problem 1_Raunak Raj_Final Concept Note.pdf']\n",
      "Duplicate files:  ['prodex_sheet (1).pdf', 'prodex_sheet.pdf']\n",
      "Duplicate files:  ['Product Development Group - 11 PPT - Milestone 2 (1).pdf', 'Product Development Group - 11 PPT - Milestone 2.pdf']\n",
      "Duplicate files:  ['Project proposal_ Robotic Fish (1).pdf', 'Project proposal_ Robotic Fish (2).pdf']\n",
      "Duplicate files:  ['SEC (1).pdf', 'SEC.pdf']\n",
      "Duplicate files:  ['sensors-22-06245 (1).pdf', 'sensors-22-06245.pdf']\n",
      "Duplicate files:  ['Shortlisted For SIH_compressed (1).pdf', 'Shortlisted For SIH_compressed.pdf']\n",
      "Duplicate files:  ['SIH Neuradecimal consent letter (1).pdf', 'SIH Neuradecimal consent letter (2).pdf', 'SIH Neuradecimal consent letter.pdf']\n",
      "Duplicate files:  ['tas-medical-certficate-new (1).pdf', 'tas-medical-certficate-new (2).pdf', 'tas-medical-certficate-new.pdf']\n",
      "Duplicate files:  ['tasafe (1).pdf', 'tasafe (2).pdf', 'tasafe.pdf']\n",
      "Duplicate files:  ['Thesis paper (1).pdf', 'Thesis paper.pdf']\n",
      "Duplicate files:  ['Wireless Compact Laser Vibrometer EDITED (1).pdf', 'Wireless Compact Laser Vibrometer EDITED.pdf']\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "# Function to calculate the hash value of a file\n",
    "def calculate_file_hash(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        hash_value = hashlib.md5(data).hexdigest()\n",
    "    return hash_value\n",
    "\n",
    "# Dictionary to store duplicate files\n",
    "duplicate_files = {}\n",
    "\n",
    "# Iterate over the PDF files and calculate hash values\n",
    "for filename in os.listdir(pdfs_folder):\n",
    "    file_path = os.path.join(pdfs_folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        hash_value = calculate_file_hash(file_path)\n",
    "        if hash_value in duplicate_files:\n",
    "            duplicate_files[hash_value].append(filename)\n",
    "        else:\n",
    "            duplicate_files[hash_value] = [filename]\n",
    "\n",
    "# Display duplicate file information\n",
    "num_duplicate_sets = len(duplicate_files)\n",
    "total_duplicate_files = sum(len(files) - 1 for files in duplicate_files.values())\n",
    "\n",
    "print(f\"Number of duplicate sets: {num_duplicate_sets}\")\n",
    "print(f\"Total number of duplicate files (excluding first files): {total_duplicate_files}\")\n",
    "\n",
    "for files in duplicate_files.values():\n",
    "    if len(files) > 1:\n",
    "        print(\"Duplicate files: \", files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>File Size (kb)</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Date Modified</th>\n",
       "      <th>Date Accessed</th>\n",
       "      <th>Number of Pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-IH-comprehensive-intellectual-humility.pdf</td>\n",
       "      <td>98.156250</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2023-04-05 15:49:53</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-lit-review-Measuring-Intellectual-Humility-...</td>\n",
       "      <td>631.642578</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2023-04-05 15:49:54</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_Task Scheduling CSP.pdf</td>\n",
       "      <td>2907.464844</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2023-04-16 11:54:27</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-Intellectual Humility An Introduction to the...</td>\n",
       "      <td>6906.728516</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2023-04-05 15:50:22</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-s2.0-S0141933118304629-main.pdf</td>\n",
       "      <td>1779.131836</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2022-11-01 13:35:09</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Untitled document.pdf</td>\n",
       "      <td>17.873047</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-11-12 12:27:02</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>week4.pdf</td>\n",
       "      <td>3177.144531</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2023-02-24 11:04:29</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Week5_lessson.pdf</td>\n",
       "      <td>189.061523</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-10-16 20:21:58</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Wireless Compact Laser Vibrometer EDITED (1).pdf</td>\n",
       "      <td>1663.701172</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-08-19 02:27:09</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Zaid Ahmed Khan Certificate.pdf</td>\n",
       "      <td>77.344727</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-11-09 18:35:44</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File Name  File Size (kb)   \n",
       "0        03-IH-comprehensive-intellectual-humility.pdf       98.156250  \\\n",
       "1    04-lit-review-Measuring-Intellectual-Humility-...      631.642578   \n",
       "2                            0_Task Scheduling CSP.pdf     2907.464844   \n",
       "3    1-Intellectual Humility An Introduction to the...     6906.728516   \n",
       "4                    1-s2.0-S0141933118304629-main.pdf     1779.131836   \n",
       "..                                                 ...             ...   \n",
       "370                              Untitled document.pdf       17.873047   \n",
       "371                                          week4.pdf     3177.144531   \n",
       "372                                  Week5_lessson.pdf      189.061523   \n",
       "373   Wireless Compact Laser Vibrometer EDITED (1).pdf     1663.701172   \n",
       "374                    Zaid Ahmed Khan Certificate.pdf       77.344727   \n",
       "\n",
       "            Date Created       Date Modified       Date Accessed   \n",
       "0    21-05-2023 21:28:42 2023-04-05 15:49:53 2023-05-22 08:59:44  \\\n",
       "1    21-05-2023 21:28:42 2023-04-05 15:49:54 2023-05-22 08:59:44   \n",
       "2    21-05-2023 21:28:42 2023-04-16 11:54:27 2023-05-22 08:59:44   \n",
       "3    21-05-2023 21:28:42 2023-04-05 15:50:22 2023-05-22 08:59:44   \n",
       "4    21-05-2023 21:28:42 2022-11-01 13:35:09 2023-05-22 08:59:44   \n",
       "..                   ...                 ...                 ...   \n",
       "370  21-05-2023 21:18:03 2022-11-12 12:27:02 2023-05-22 08:59:49   \n",
       "371  21-05-2023 21:18:03 2023-02-24 11:04:29 2023-05-22 08:59:49   \n",
       "372  21-05-2023 21:18:03 2022-10-16 20:21:58 2023-05-22 08:59:49   \n",
       "373  21-05-2023 21:18:03 2022-08-19 02:27:09 2023-05-22 08:59:49   \n",
       "374  21-05-2023 21:18:03 2022-11-09 18:35:44 2023-05-22 08:59:49   \n",
       "\n",
       "     Number of Pages  \n",
       "0                  3  \n",
       "1                 11  \n",
       "2                  9  \n",
       "3                369  \n",
       "4                 14  \n",
       "..               ...  \n",
       "370                1  \n",
       "371               94  \n",
       "372                4  \n",
       "373               12  \n",
       "374                1  \n",
       "\n",
       "[375 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List to store the indices of rows to be removed\n",
    "rows_to_remove = []\n",
    "\n",
    "# Iterate over the duplicate files and find the indices of the rows to be removed\n",
    "for files in duplicate_files.values():\n",
    "    if len(files) > 1:\n",
    "        duplicate_filenames = files[1:]  # Exclude the first file in each set\n",
    "        for index, row in df.iterrows():\n",
    "            if row['File Name'] in duplicate_filenames:\n",
    "                rows_to_remove.append(index)\n",
    "\n",
    "# Remove the rows from the DataFrame\n",
    "df = df.drop(rows_to_remove)\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved file to recycle bin: All_PDFs\\AI4CPS_Search_1.pdf\n",
      "Moved file to recycle bin: All_PDFs\\attachment (5).pdf\n",
      "Moved file to recycle bin: All_PDFs\\attachment (6).pdf\n",
      "Moved file to recycle bin: All_PDFs\\attachment.pdf\n",
      "Moved file to recycle bin: All_PDFs\\attachment (9).pdf\n",
      "Moved file to recycle bin: All_PDFs\\attachment (3).pdf\n",
      "Moved file to recycle bin: All_PDFs\\BTP-1 Consent Form.pdf\n",
      "Moved file to recycle bin: All_PDFs\\CCU_NAG_2022-08-24_OLWZVS (2).pdf\n",
      "Moved file to recycle bin: All_PDFs\\CCU_NAG_2022-08-24_OLWZVS.pdf\n",
      "Moved file to recycle bin: All_PDFs\\CentuRITon_Idea_AuReal_PPT.pdf\n",
      "Moved file to recycle bin: All_PDFs\\DOC-20230207-WA0000..pdf\n",
      "Moved file to recycle bin: All_PDFs\\downloadRegistrationCard.pdf\n",
      "Moved file to recycle bin: All_PDFs\\UTIITSL_ePAN_CYWPM4396M_03042023_213849.pdf\n",
      "Moved file to recycle bin: All_PDFs\\FAQ_2023_Application-Requirements.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Final_Schedule_for_SIH_2022_Software_25_to_26th_August_2022_2 (2).pdf\n",
      "Moved file to recycle bin: All_PDFs\\Final_Schedule_for_SIH_2022_Software_25_to_26th_August_2022_2 (3).pdf\n",
      "Moved file to recycle bin: All_PDFs\\Final_Schedule_for_SIH_2022_Software_25_to_26th_August_2022_2.pdf\n",
      "Moved file to recycle bin: All_PDFs\\FTS-koren.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Gmail - Final Report Submission Problem Statement-1 (1).pdf\n",
      "Moved file to recycle bin: All_PDFs\\IIT Kanpur Webmail __ [Meug] JHU-MechE Summer Intership Program for Rising Seniors.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Keerthi Sree Marrapu.pdf\n",
      "Moved file to recycle bin: All_PDFs\\qdoc.tips_heat-transfer-by-yvc-rao.pdf\n",
      "Moved file to recycle bin: All_PDFs\\me_ntmp_18_ps_intro.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Micro_2014-2015.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Micro_2022-2023_Updated.pdf\n",
      "Moved file to recycle bin: All_PDFs\\MKSree_CV (4).pdf\n",
      "Moved file to recycle bin: All_PDFs\\MKSree_ERP_CV1.pdf\n",
      "Moved file to recycle bin: All_PDFs\\MKS_CV_Jul_2022_ERP_Verified (1).pdf\n",
      "Moved file to recycle bin: All_PDFs\\MKS_CV_Jul_2022_ERP_Verified.pdf\n",
      "Moved file to recycle bin: All_PDFs\\toaz.info-a-textbook-of-vastuvidya-prabhu-1996-pr_c3b9e6b585ea60d200ef191456b68ca9.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Problem 1_Raunak Raj_Final Concept Note.pdf\n",
      "Moved file to recycle bin: All_PDFs\\prodex_sheet.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Product Development Group - 11 PPT - Milestone 2.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Project proposal_ Robotic Fish (2).pdf\n",
      "Moved file to recycle bin: All_PDFs\\SEC.pdf\n",
      "Moved file to recycle bin: All_PDFs\\sensors-22-06245.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Shortlisted For SIH_compressed.pdf\n",
      "Moved file to recycle bin: All_PDFs\\SIH Neuradecimal consent letter (2).pdf\n",
      "Moved file to recycle bin: All_PDFs\\SIH Neuradecimal consent letter.pdf\n",
      "Moved file to recycle bin: All_PDFs\\tas-medical-certficate-new (2).pdf\n",
      "Moved file to recycle bin: All_PDFs\\tas-medical-certficate-new.pdf\n",
      "Moved file to recycle bin: All_PDFs\\tasafe (2).pdf\n",
      "Moved file to recycle bin: All_PDFs\\tasafe.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Thesis paper.pdf\n",
      "Moved file to recycle bin: All_PDFs\\Wireless Compact Laser Vibrometer EDITED.pdf\n",
      "Duplicate files moved to the recycle bin successfully.\n"
     ]
    }
   ],
   "source": [
    "import send2trash\n",
    "\n",
    "# Dictionary to store duplicate files\n",
    "duplicate_files = {}\n",
    "\n",
    "# Iterate over the PDF files and calculate hash values\n",
    "for filename in os.listdir(pdfs_folder):\n",
    "    file_path = os.path.join(pdfs_folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        hash_value = calculate_file_hash(file_path)\n",
    "        if hash_value in duplicate_files:\n",
    "            duplicate_files[hash_value].append(file_path)\n",
    "        else:\n",
    "            duplicate_files[hash_value] = [file_path]\n",
    "\n",
    "# Move duplicate files to the recycle bin\n",
    "for files in duplicate_files.values():\n",
    "    if len(files) > 1:\n",
    "        # Keep the first file and move the rest to the recycle bin\n",
    "        files_to_move = files[1:]\n",
    "        for file_to_move in files_to_move:\n",
    "            try:\n",
    "                send2trash.send2trash(file_to_move)\n",
    "                print(f\"Moved file to recycle bin: {file_to_move}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error moving file to recycle bin: {file_to_move} - {str(e)}\")\n",
    "\n",
    "print(\"Duplicate files moved to the recycle bin successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pdfs = 375\n",
      "Total memory occupied by pdfs = 906.2167615890503 MB\n",
      "Number of pdfs not opened since 6 months =  0\n",
      "Number of pdfs not modified since 6 months =  241\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "df['Date Accessed'] = pd.to_datetime(df['Date Accessed'], format='%d-%m-%Y %H:%M:%S')\n",
    "df['Date Modified'] = pd.to_datetime(df['Date Modified'], format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "\n",
    "print(f\"Number of pdfs = {df.shape[0]}\")\n",
    "total_memory = df[\"File Size (kb)\"].sum() / 1024\n",
    "\n",
    "print(f\"Total memory occupied by pdfs = {total_memory} MB\")\n",
    "\n",
    "time_gap = datetime.now() - timedelta(days=182)\n",
    "filtered_df = df[df['Date Accessed'] < time_gap]\n",
    "filtered_df2 = df[df['Date Modified'] < time_gap]\n",
    "\n",
    "\n",
    "count = filtered_df.shape[0]\n",
    "count2 = filtered_df2.shape[0]\n",
    "\n",
    "print(\"Number of pdfs not opened since 6 months = \", count)\n",
    "print(\"Number of pdfs not modified since 6 months = \", count2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate sets: 382\n",
      "Total number of duplicate files (excluding first files): 0\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store duplicate files\n",
    "duplicate_files = {}\n",
    "\n",
    "# Iterate over the PDF files and calculate hash values\n",
    "for filename in os.listdir(pdfs_folder):\n",
    "    file_path = os.path.join(pdfs_folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        hash_value = calculate_file_hash(file_path)\n",
    "        if hash_value in duplicate_files:\n",
    "            duplicate_files[hash_value].append(filename)\n",
    "        else:\n",
    "            duplicate_files[hash_value] = [filename]\n",
    "\n",
    "# Display duplicate file information\n",
    "num_duplicate_sets = len(duplicate_files)\n",
    "total_duplicate_files = sum(len(files) - 1 for files in duplicate_files.values())\n",
    "\n",
    "print(f\"Number of duplicate sets: {num_duplicate_sets}\")\n",
    "print(f\"Total number of duplicate files (excluding first files): {total_duplicate_files}\")\n",
    "\n",
    "for files in duplicate_files.values():\n",
    "    if len(files) > 1:\n",
    "        print(\"Duplicate files: \", files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfparent=df.copy(deep=True)\n",
    "df=dfparent[dfparent[\"Number of Pages\"]<60].copy(deep=True)\n",
    "dfbigfile=dfparent[dfparent[\"Number of Pages\"]>=60].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   1%|▏         | 5/347 [00:02<03:02,  1.87file/s]FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "Processing PDFs:   2%|▏         | 8/347 [00:08<08:39,  1.53s/file]FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "Processing PDFs:   8%|▊         | 28/347 [00:28<03:42,  1.43file/s]FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10498687') invalid; use 0.0 instead\n",
      "Processing PDFs:  41%|████      | 142/347 [02:00<04:29,  1.31s/file]unknown widths : \n",
      "[0, IndirectObject(44, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(114, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(109, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(104, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(99, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(69, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(94, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(39, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(64, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(54, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(74, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(89, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(74, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(69, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(64, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(59, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(54, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(49, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(44, 0, 2094670495440)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(39, 0, 2094670495440)]\n",
      "Processing PDFs:  69%|██████▊   | 238/347 [03:03<03:40,  2.02s/file]FloatObject (b'0.00-2370739') invalid; use 0.0 instead\n",
      "Processing PDFs:  91%|█████████▏| 317/347 [04:27<00:33,  1.12s/file]Multiple definitions in dictionary at byte 0x6439e for key /Info\n",
      "Multiple definitions in dictionary at byte 0x643ab for key /Info\n",
      "Multiple definitions in dictionary at byte 0x643b8 for key /Info\n",
      "Processing PDFs:  98%|█████████▊| 340/347 [04:38<00:02,  2.66file/s]Multiple definitions in dictionary at byte 0x3076e for key /Info\n",
      "Multiple definitions in dictionary at byte 0x3077a for key /Info\n",
      "Multiple definitions in dictionary at byte 0x30786 for key /Info\n",
      "Processing PDFs: 100%|██████████| 347/347 [04:38<00:00,  1.25file/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>File Size (kb)</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Date Modified</th>\n",
       "      <th>Date Accessed</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Text Extracted</th>\n",
       "      <th>Text_Ext_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-IH-comprehensive-intellectual-humility.pdf</td>\n",
       "      <td>98.156250</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2023-04-05 15:49:53</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>3</td>\n",
       "      <td>\\n \\n             \\n      \\n  \\n \\...</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-lit-review-Measuring-Intellectual-Humility-...</td>\n",
       "      <td>631.642578</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2023-04-05 15:49:54</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>11</td>\n",
       "      <td>Measur ing Intellectual Humility  in an Online...</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_Task Scheduling CSP.pdf</td>\n",
       "      <td>2907.464844</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2023-04-16 11:54:27</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>9</td>\n",
       "      <td>. \\n11 elo it \\nntg u dtar ttme eustraaliE \\nf...</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-s2.0-S0141933118304629-main.pdf</td>\n",
       "      <td>1779.131836</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2022-11-01 13:35:09</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>14</td>\n",
       "      <td>Microprocessors  and Microsystems  70 (2019) 1...</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1-s2.0-S0169131706002043-main.pdf</td>\n",
       "      <td>486.779297</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2022-12-10 20:36:46</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>9</td>\n",
       "      <td>Controlling green sand mould properties using ...</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Unsafe_Patient_Handling.5.pdf</td>\n",
       "      <td>1093.536133</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-08-09 16:48:12</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>1</td>\n",
       "      <td>ajn@wolterskluwer.com  AJN  January 2019   Vol...</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Untitled document.pdf</td>\n",
       "      <td>17.873047</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-11-12 12:27:02</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>1</td>\n",
       "      <td>Mini\\nStatements\\nattesting\\nreceiving\\nprize\\...</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Week5_lessson.pdf</td>\n",
       "      <td>189.061523</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-10-16 20:21:58</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>4</td>\n",
       "      <td>Tasks for 12/09/2022  and 19/09/2022 : \\n(Prob...</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Wireless Compact Laser Vibrometer EDITED (1).pdf</td>\n",
       "      <td>1663.701172</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-08-19 02:27:09</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>12</td>\n",
       "      <td>Wireless Compact Laser Vibrometer\\nIdea/A ppro...</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Zaid Ahmed Khan Certificate.pdf</td>\n",
       "      <td>77.344727</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-11-09 18:35:44</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>1</td>\n",
       "      <td>Presented to Zaid Ahmed Khan  of Indian Instit...</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>347 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File Name  File Size (kb)   \n",
       "0        03-IH-comprehensive-intellectual-humility.pdf       98.156250  \\\n",
       "1    04-lit-review-Measuring-Intellectual-Humility-...      631.642578   \n",
       "2                            0_Task Scheduling CSP.pdf     2907.464844   \n",
       "4                    1-s2.0-S0141933118304629-main.pdf     1779.131836   \n",
       "5                    1-s2.0-S0169131706002043-main.pdf      486.779297   \n",
       "..                                                 ...             ...   \n",
       "369                      Unsafe_Patient_Handling.5.pdf     1093.536133   \n",
       "370                              Untitled document.pdf       17.873047   \n",
       "372                                  Week5_lessson.pdf      189.061523   \n",
       "373   Wireless Compact Laser Vibrometer EDITED (1).pdf     1663.701172   \n",
       "374                    Zaid Ahmed Khan Certificate.pdf       77.344727   \n",
       "\n",
       "            Date Created       Date Modified       Date Accessed   \n",
       "0    21-05-2023 21:28:42 2023-04-05 15:49:53 2023-05-22 08:59:44  \\\n",
       "1    21-05-2023 21:28:42 2023-04-05 15:49:54 2023-05-22 08:59:44   \n",
       "2    21-05-2023 21:28:42 2023-04-16 11:54:27 2023-05-22 08:59:44   \n",
       "4    21-05-2023 21:28:42 2022-11-01 13:35:09 2023-05-22 08:59:44   \n",
       "5    21-05-2023 21:28:42 2022-12-10 20:36:46 2023-05-22 08:59:44   \n",
       "..                   ...                 ...                 ...   \n",
       "369  21-05-2023 21:18:03 2022-08-09 16:48:12 2023-05-22 08:59:49   \n",
       "370  21-05-2023 21:18:03 2022-11-12 12:27:02 2023-05-22 08:59:49   \n",
       "372  21-05-2023 21:18:03 2022-10-16 20:21:58 2023-05-22 08:59:49   \n",
       "373  21-05-2023 21:18:03 2022-08-19 02:27:09 2023-05-22 08:59:49   \n",
       "374  21-05-2023 21:18:03 2022-11-09 18:35:44 2023-05-22 08:59:49   \n",
       "\n",
       "     Number of Pages                                     Text Extracted   \n",
       "0                  3              \\n \\n             \\n      \\n  \\n \\...  \\\n",
       "1                 11  Measur ing Intellectual Humility  in an Online...   \n",
       "2                  9  . \\n11 elo it \\nntg u dtar ttme eustraaliE \\nf...   \n",
       "4                 14  Microprocessors  and Microsystems  70 (2019) 1...   \n",
       "5                  9  Controlling green sand mould properties using ...   \n",
       "..               ...                                                ...   \n",
       "369                1  ajn@wolterskluwer.com  AJN  January 2019   Vol...   \n",
       "370                1  Mini\\nStatements\\nattesting\\nreceiving\\nprize\\...   \n",
       "372                4  Tasks for 12/09/2022  and 19/09/2022 : \\n(Prob...   \n",
       "373               12  Wireless Compact Laser Vibrometer\\nIdea/A ppro...   \n",
       "374                1  Presented to Zaid Ahmed Khan  of Indian Instit...   \n",
       "\n",
       "    Text_Ext_Status  \n",
       "0              Done  \n",
       "1              Done  \n",
       "2              Done  \n",
       "4              Done  \n",
       "5              Done  \n",
       "..              ...  \n",
       "369            Done  \n",
       "370            Done  \n",
       "372            Done  \n",
       "373            Done  \n",
       "374            Done  \n",
       "\n",
       "[347 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Function to extract text from a PDF file using OCR\n",
    "def extract_text_from_pdf(file_path):\n",
    "    start_time = time.time()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        pdf = PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            if time.time() - start_time > 30:\n",
    "                return None  # Interrupt extraction if it takes more than 30 seconds\n",
    "            if hasattr(page, 'Resources') and \"/XObject\" in page.Resources.keys():\n",
    "                x_objects = page.Resources['/XObject'].getObject()\n",
    "                for obj in x_objects:\n",
    "                    if x_objects[obj]['/Subtype'] == '/Image':\n",
    "                        # Convert image to PIL Image object\n",
    "                        img = Image.frombytes(\n",
    "                            x_objects[obj]['/ColorSpace'] if '/ColorSpace' in x_objects[obj] else '/DeviceRGB',\n",
    "                            (x_objects[obj]['/Width'], x_objects[obj]['/Height']),\n",
    "                            x_objects[obj].getData()\n",
    "                        )\n",
    "                        # Perform OCR on the image\n",
    "                        extracted_text = pytesseract.image_to_string(img)\n",
    "                        # Remove invalid characters from extracted text\n",
    "                        cleaned_text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", extracted_text)\n",
    "                        text += cleaned_text\n",
    "            else:\n",
    "                extracted_text = page.extract_text()\n",
    "                cleaned_text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", extracted_text)\n",
    "                text += cleaned_text\n",
    "        \n",
    "        return text\n",
    "\n",
    "# Get the total number of PDF files\n",
    "total_files = len(df)\n",
    "\n",
    "# Initialize progress bar\n",
    "pbar = tqdm(total=total_files, desc=\"Processing PDFs\", unit=\"file\")\n",
    "\n",
    "# Extract text for each PDF file and update the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    file_name = row[\"File Name\"]\n",
    "    file_path = os.path.join(pdfs_folder, file_name)\n",
    "    try:\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "        if text is not None:\n",
    "            df.at[index, \"Text Extracted\"] = text\n",
    "            df.at[index, \"Text_Ext_Status\"] = \"Done\"\n",
    "        \n",
    "        else:\n",
    "            df.at[index, \"Text_Ext_Status\"] = \"Interrupted due to too much time\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from file: {file_name} - {str(e)}\")\n",
    "        df.at[index, \"Text Extracted\"] = \"\"\n",
    "        df.at[index, \"Text_Ext_Status\"] = \"Error\"\n",
    "    \n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "# Close the progress bar\n",
    "pbar.close()\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Keywords: 100%|██████████| 347/347 [00:04<00:00, 72.38file/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>File Size (kb)</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Date Modified</th>\n",
       "      <th>Date Accessed</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Text Extracted</th>\n",
       "      <th>Text_Ext_Status</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-IH-comprehensive-intellectual-humility.pdf</td>\n",
       "      <td>98.156250</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2023-04-05 15:49:53</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>3</td>\n",
       "      <td>\\n \\n             \\n      \\n  \\n \\...</td>\n",
       "      <td>Done</td>\n",
       "      <td>[openness, insignificant, scores, tally, aster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-lit-review-Measuring-Intellectual-Humility-...</td>\n",
       "      <td>631.642578</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2023-04-05 15:49:54</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>11</td>\n",
       "      <td>Measur ing Intellectual Humility  in an Online...</td>\n",
       "      <td>Done</td>\n",
       "      <td>[afliation, education, race, gender, ng, inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_Task Scheduling CSP.pdf</td>\n",
       "      <td>2907.464844</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2023-04-16 11:54:27</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>9</td>\n",
       "      <td>. \\n11 elo it \\nntg u dtar ttme eustraaliE \\nf...</td>\n",
       "      <td>Done</td>\n",
       "      <td>[mr, ddtal, mn, b2, ruus, puoaor, pvoosox, poc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-s2.0-S0141933118304629-main.pdf</td>\n",
       "      <td>1779.131836</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2022-11-01 13:35:09</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>14</td>\n",
       "      <td>Microprocessors  and Microsystems  70 (2019) 1...</td>\n",
       "      <td>Done</td>\n",
       "      <td>[member, ference, reviewed, articles, magazine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1-s2.0-S0169131706002043-main.pdf</td>\n",
       "      <td>486.779297</td>\n",
       "      <td>21-05-2023 21:28:42</td>\n",
       "      <td>2022-12-10 20:36:46</td>\n",
       "      <td>2023-05-22 08:59:44</td>\n",
       "      <td>9</td>\n",
       "      <td>Controlling green sand mould properties using ...</td>\n",
       "      <td>Done</td>\n",
       "      <td>[fines, 254, 243, 38, recycling, conservation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Unsafe_Patient_Handling.5.pdf</td>\n",
       "      <td>1093.536133</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-08-09 16:48:12</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>1</td>\n",
       "      <td>ajn@wolterskluwer.com  AJN  January 2019   Vol...</td>\n",
       "      <td>Done</td>\n",
       "      <td>[etc, fax, 212, 10001, ny, york, new, floor, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Untitled document.pdf</td>\n",
       "      <td>17.873047</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-11-12 12:27:02</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>1</td>\n",
       "      <td>Mini\\nStatements\\nattesting\\nreceiving\\nprize\\...</td>\n",
       "      <td>Done</td>\n",
       "      <td>[punbh22313399079, xx9051, raj, raunak, finali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Week5_lessson.pdf</td>\n",
       "      <td>189.061523</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-10-16 20:21:58</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>4</td>\n",
       "      <td>Tasks for 12/09/2022  and 19/09/2022 : \\n(Prob...</td>\n",
       "      <td>Done</td>\n",
       "      <td>[54, meshgrid, numpy, need, matrices, coeffici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Wireless Compact Laser Vibrometer EDITED (1).pdf</td>\n",
       "      <td>1663.701172</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-08-19 02:27:09</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>12</td>\n",
       "      <td>Wireless Compact Laser Vibrometer\\nIdea/A ppro...</td>\n",
       "      <td>Done</td>\n",
       "      <td>[feedback, sales, finally, framework, manufact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Zaid Ahmed Khan Certificate.pdf</td>\n",
       "      <td>77.344727</td>\n",
       "      <td>21-05-2023 21:18:03</td>\n",
       "      <td>2022-11-09 18:35:44</td>\n",
       "      <td>2023-05-22 08:59:49</td>\n",
       "      <td>1</td>\n",
       "      <td>Presented to Zaid Ahmed Khan  of Indian Instit...</td>\n",
       "      <td>Done</td>\n",
       "      <td>[chair, program, certicate, challenge, design,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>347 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File Name  File Size (kb)   \n",
       "0        03-IH-comprehensive-intellectual-humility.pdf       98.156250  \\\n",
       "1    04-lit-review-Measuring-Intellectual-Humility-...      631.642578   \n",
       "2                            0_Task Scheduling CSP.pdf     2907.464844   \n",
       "4                    1-s2.0-S0141933118304629-main.pdf     1779.131836   \n",
       "5                    1-s2.0-S0169131706002043-main.pdf      486.779297   \n",
       "..                                                 ...             ...   \n",
       "369                      Unsafe_Patient_Handling.5.pdf     1093.536133   \n",
       "370                              Untitled document.pdf       17.873047   \n",
       "372                                  Week5_lessson.pdf      189.061523   \n",
       "373   Wireless Compact Laser Vibrometer EDITED (1).pdf     1663.701172   \n",
       "374                    Zaid Ahmed Khan Certificate.pdf       77.344727   \n",
       "\n",
       "            Date Created       Date Modified       Date Accessed   \n",
       "0    21-05-2023 21:28:42 2023-04-05 15:49:53 2023-05-22 08:59:44  \\\n",
       "1    21-05-2023 21:28:42 2023-04-05 15:49:54 2023-05-22 08:59:44   \n",
       "2    21-05-2023 21:28:42 2023-04-16 11:54:27 2023-05-22 08:59:44   \n",
       "4    21-05-2023 21:28:42 2022-11-01 13:35:09 2023-05-22 08:59:44   \n",
       "5    21-05-2023 21:28:42 2022-12-10 20:36:46 2023-05-22 08:59:44   \n",
       "..                   ...                 ...                 ...   \n",
       "369  21-05-2023 21:18:03 2022-08-09 16:48:12 2023-05-22 08:59:49   \n",
       "370  21-05-2023 21:18:03 2022-11-12 12:27:02 2023-05-22 08:59:49   \n",
       "372  21-05-2023 21:18:03 2022-10-16 20:21:58 2023-05-22 08:59:49   \n",
       "373  21-05-2023 21:18:03 2022-08-19 02:27:09 2023-05-22 08:59:49   \n",
       "374  21-05-2023 21:18:03 2022-11-09 18:35:44 2023-05-22 08:59:49   \n",
       "\n",
       "     Number of Pages                                     Text Extracted   \n",
       "0                  3              \\n \\n             \\n      \\n  \\n \\...  \\\n",
       "1                 11  Measur ing Intellectual Humility  in an Online...   \n",
       "2                  9  . \\n11 elo it \\nntg u dtar ttme eustraaliE \\nf...   \n",
       "4                 14  Microprocessors  and Microsystems  70 (2019) 1...   \n",
       "5                  9  Controlling green sand mould properties using ...   \n",
       "..               ...                                                ...   \n",
       "369                1  ajn@wolterskluwer.com  AJN  January 2019   Vol...   \n",
       "370                1  Mini\\nStatements\\nattesting\\nreceiving\\nprize\\...   \n",
       "372                4  Tasks for 12/09/2022  and 19/09/2022 : \\n(Prob...   \n",
       "373               12  Wireless Compact Laser Vibrometer\\nIdea/A ppro...   \n",
       "374                1  Presented to Zaid Ahmed Khan  of Indian Instit...   \n",
       "\n",
       "    Text_Ext_Status                                           Keywords  \n",
       "0              Done  [openness, insignificant, scores, tally, aster...  \n",
       "1              Done  [afliation, education, race, gender, ng, inclu...  \n",
       "2              Done  [mr, ddtal, mn, b2, ruus, puoaor, pvoosox, poc...  \n",
       "4              Done  [member, ference, reviewed, articles, magazine...  \n",
       "5              Done  [fines, 254, 243, 38, recycling, conservation,...  \n",
       "..              ...                                                ...  \n",
       "369            Done  [etc, fax, 212, 10001, ny, york, new, floor, 1...  \n",
       "370            Done  [punbh22313399079, xx9051, raj, raunak, finali...  \n",
       "372            Done  [54, meshgrid, numpy, need, matrices, coeffici...  \n",
       "373            Done  [feedback, sales, finally, framework, manufact...  \n",
       "374            Done  [chair, program, certicate, challenge, design,...  \n",
       "\n",
       "[347 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to extract keywords from text\n",
    "def extract_keywords(text):\n",
    "    # Tokenize the text into individual words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Perform any preprocessing or filtering on the tokens as needed\n",
    "    \n",
    "    # Remove punctuation and convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens if token.isalnum()]\n",
    "    \n",
    "    # Check if the tokens are empty or contain only stop words\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    valid_tokens = [token for token in tokens if token not in stop_words]\n",
    "    if not valid_tokens:\n",
    "        return []\n",
    "    \n",
    "    # Extract the keywords using TF-IDF algorithm\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform([\" \".join(valid_tokens)])  # Join valid tokens back into a single string\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "    keyword_indices = tfidf_matrix[0].nonzero()[1]\n",
    "    keywords = [feature_names[idx] for idx in keyword_indices]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "# Get the total number of PDF files\n",
    "total_files = len(df)\n",
    "\n",
    "# Initialize progress bar\n",
    "pbar = tqdm(total=total_files, desc=\"Extracting Keywords\", unit=\"file\")\n",
    "\n",
    "# Apply keyword extraction to each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    text = row[\"Text Extracted\"]\n",
    "    \n",
    "    if isinstance(text, str):  # Check if text is a string\n",
    "        if text.strip() == \"\":\n",
    "            keywords_str = \"\"\n",
    "        else:\n",
    "            keywords = extract_keywords(text)\n",
    "            keywords_str = \", \".join(keywords) if keywords else \"\"  # Convert the list of keywords to a comma-separated string if not empty\n",
    "    else:\n",
    "        keywords_str = \"\"\n",
    "    \n",
    "    df.at[index, \"Keywords\"] = keywords_str\n",
    "    \n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "# Close the progress bar\n",
    "pbar.close()\n",
    "\n",
    "\n",
    "def word_splt(text):\n",
    "    if isinstance(text, float): \n",
    "        words_list = None\n",
    "        \n",
    "    else: \n",
    "        words_list = text.split(\", \")\n",
    "    \n",
    "    return words_list\n",
    "\n",
    "df[\"Keywords\"] = df[\"Keywords\"].apply(word_splt)\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df['Text Extracted'] = df['Text Extracted'].fillna('').astype(str)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "text_vectors = vectorizer.fit_transform(df['Text Extracted'])\n",
    "\n",
    "def search_files(query, top_k=10):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vector, text_vectors).flatten()\n",
    "    indices = similarities.argsort()[::-1][:top_k]\n",
    "    return df.iloc[indices]['File Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MKSree CV 210122.pdf', 'Modern_Deedy (2).pdf', 'Modern_Deedy (1).pdf', 'MKSree_CV (7).pdf', 'MKSree_CV (9).pdf', 'MKSree_CV (8).pdf', 'MKSree_CV (6).pdf', 'MKSree_CV (4) (1).pdf', 'MKSree_CV (3).pdf', 'MKSree_CV (2).pdf']\n"
     ]
    }
   ],
   "source": [
    "search_query = 'education'\n",
    "relevant_files = search_files(search_query)\n",
    "print(relevant_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\keerthi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\keerthi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Convert the text data into TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Text Extracted'])\n",
    "\n",
    "# Perform clustering using K-means\n",
    "num_clusters = 5  # Number of clusters to create\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "# Assign cluster labels to the DataFrame\n",
    "df['Cluster Label'] = kmeans.labels_\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Combine text, file name, and file size for clustering\n",
    "df2['Text'] = df['Text Extracted']\n",
    "df2['File Name'] = df['File Name'].apply(lambda x: os.path.splitext(x)[0])  # Remove file extension\n",
    "df2['File Size'] = df['File Size (kb)']\n",
    "cluster_data = df2[['Text', 'File Name', 'File Size']]\n",
    "\n",
    "\n",
    "# Define the column transformer to handle different variable types\n",
    "column_transformer = make_column_transformer(\n",
    "    (TfidfVectorizer(), 'Text'),\n",
    "    (StandardScaler(), ['File Size'])\n",
    ")\n",
    "\n",
    "# Create the pipeline for clustering\n",
    "pipeline = make_pipeline(column_transformer, KMeans(n_clusters=num_clusters, random_state=42))\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "pipeline.fit(cluster_data)\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df['Cluster'] = pipeline.predict(cluster_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Create a directory to store the clusters\n",
    "clusters_dir = pdfs_folder\n",
    "os.makedirs(clusters_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over the clusters\n",
    "for cluster_id in range(num_clusters):\n",
    "    # Create a directory for each cluster\n",
    "    cluster_dir = os.path.join(clusters_dir, f\"Cluster_{cluster_id}\")\n",
    "    os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "    # Get the PDFs in the current cluster\n",
    "    cluster_pdf_names = df[df[\"Cluster Label\"] == cluster_id][\"File Name\"]\n",
    "\n",
    "    # Move the PDFs to the cluster directory\n",
    "    for pdf_name in cluster_pdf_names:\n",
    "        src_path = os.path.join(pdfs_folder, pdf_name)\n",
    "        dst_path = os.path.join(cluster_dir, pdf_name)\n",
    "        shutil.move(src_path, dst_path)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "cluster_dir = os.path.join(clusters_dir, f\"Cluster_Bigfiles\")\n",
    "os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "# Get the PDFs in the current cluster\n",
    "cluster_pdf_names = dfbigfile[\"File Name\"]\n",
    "\n",
    "# Move the PDFs to the cluster directory\n",
    "for pdf_name in cluster_pdf_names:\n",
    "    src_path = os.path.join(pdfs_folder, pdf_name)\n",
    "    dst_path = os.path.join(cluster_dir, pdf_name)\n",
    "    shutil.move(src_path, dst_path)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory where the PDFs will be moved\n",
    "output_directory = pdfs_folder\n",
    "\n",
    "# Iterate over each cluster\n",
    "for cluster_id in range(num_clusters):\n",
    "    # Create a folder for the cluster\n",
    "    cluster_folder = os.path.join(output_directory, f\"Cluster_{cluster_id}\")\n",
    "    os.makedirs(cluster_folder, exist_ok=True)\n",
    "\n",
    "    # Filter the DataFrame to get the PDFs belonging to the current cluster\n",
    "    cluster_df = df[df['Cluster Label'] == cluster_id]\n",
    "\n",
    "    # Move the PDF files from the cluster folder to their original locations\n",
    "    for _, row in cluster_df.iterrows():\n",
    "        try: \n",
    "            file_name = row['File Name']\n",
    "            original_path = os.path.join(pdfs_folder, file_name)\n",
    "            new_path = os.path.join(cluster_folder, file_name)\n",
    "            shutil.move(new_path, original_path)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "cluster_folder = os.path.join(output_directory, f\"Cluster_Bigfiles\")\n",
    "os.makedirs(cluster_folder, exist_ok=True)\n",
    "\n",
    "# Filter the DataFrame to get the PDFs belonging to the current cluster\n",
    "cluster_df = dfbigfile\n",
    "\n",
    "# Move the PDF files from the cluster folder to their original locations\n",
    "for _, row in cluster_df.iterrows():\n",
    "    try: \n",
    "        file_name = row['File Name']\n",
    "        original_path = os.path.join(pdfs_folder, file_name)\n",
    "        new_path = os.path.join(cluster_folder, file_name)\n",
    "        shutil.move(new_path, original_path)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Delete empty folders in the output directory\n",
    "for cluster_id in range(num_clusters):\n",
    "    cluster_folder = os.path.join(output_directory, f\"Cluster_{cluster_id}\")\n",
    "    if os.path.isdir(cluster_folder) and len(os.listdir(cluster_folder)) == 0:\n",
    "        os.rmdir(cluster_folder)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "cluster_folder = os.path.join(output_directory, f\"Cluster_Bigfiles\")\n",
    "if os.path.isdir(cluster_folder) and len(os.listdir(cluster_folder)) == 0:\n",
    "    os.rmdir(cluster_folder)\n",
    "#-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
